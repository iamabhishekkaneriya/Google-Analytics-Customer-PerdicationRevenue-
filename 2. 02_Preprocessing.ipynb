# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv('data/customer_data.csv')

# Handle missing values - Filling missing values with 0
data.fillna(0, inplace=True)

# Encoding categorical variables (if any)
data = pd.get_dummies(data, drop_first=True)

# Feature scaling (standardizing numerical features)
scaler = StandardScaler()
numerical_columns = ['feature1', 'feature2', 'feature3']  # Replace with actual numerical columns
data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Split the data into features (X) and target variable (y)
X = data.drop('revenue', axis=1)  # 'revenue' is the target
y = data['revenue']

# Split the data into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Save the processed data (optional)
X_train.to_csv('data/X_train.csv', index=False)
X_test.to_csv('data/X_test.csv', index=False)
y_train.to_csv('data/y_train.csv', index=False)
y_test.to_csv('data/y_test.csv', index=False)
